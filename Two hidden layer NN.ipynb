{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid (x):\n",
    "return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Derivative of Sigmoid Function\n",
    "def sigmoid_b(x):\n",
    "return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just define the values of X & y. \n",
    "# Let input X be of shape [None,no_of_features]\n",
    "# Let y be of shape [None,out_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch=10\n",
    "learning_rate=0.01\n",
    "\n",
    "# Initialization of W & b\n",
    "W1=np.random.uniform(size=(no_of_features,hidden1_neurons))\n",
    "b1=np.random.uniform(size=(1,hidden1_neurons))\n",
    "W2=np.random.uniform(size=(hidden1_neurons,hidden2_neurons))\n",
    "b2=np.random.uniform(size=(1,hidden2_neurons))\n",
    "W3=np.random.uniform(size=(hidden2_neurons,out_neurons))\n",
    "b3=np.random.uniform(size=(1,out_neurons))\n",
    "\n",
    "\n",
    "\n",
    "for steps in range(epochs):\n",
    "    # FEED-FORWARD\n",
    "    \n",
    "    h1 = np.dot(W1,X)+ b1\n",
    "    h11 = sigmoid(h1)\n",
    "\n",
    "    h2 = np.dot(W2,h11) + b2\n",
    "    h22 = sigmoid(h2)\n",
    "\n",
    "    output_layer = np.dot(W3,h22) + b3\n",
    "    y = sigmoid(h3)     \n",
    "    \n",
    "    \n",
    "    # Calculate the error/loss\n",
    "    loss  = ((1 / 2) * (np.power((y_true - y), 2)))\n",
    "    \n",
    "    # Backprop\n",
    "    # 1) Calculate the derivatives\n",
    "    output_layer_slope = sigmoid_b(y)\n",
    "    hidden_layer1_slope = sigmoid_b(h22)\n",
    "    hidden_layer2_slope = sigmoid_b(h11)\n",
    "    \n",
    "    d_output = loss*output_layer_slope   #delta at output layer\n",
    "    Error_at_hidden_layer1 = d_output.dot(W3.T)\n",
    "    d_hidden1 = Error_at_hidden_layer1 * hidden_layer1_slope  #delta at hidden layer1\n",
    "    Error_at_hidden_layer2 = d_hidden2.dot(W2.T)\n",
    "    d_hidden2 = Error_at_hidden_layer2 * hidden_layer2_slope    #delta at hidden layer 2\n",
    "    \n",
    "    # 2) Update the weights\n",
    "    W3 += h22.T.dot(d_output) * learning_rate\n",
    "    b3 += np.sum(d_output,axis=0) * learning_rate\n",
    "    W2 += h11.T.dot(d_hidden1) * learning_rate\n",
    "    b2 += np.sum(d_hidden1,axis=0) * learning_rate\n",
    "    W1 += X.T.dot(d_hidden2) * learning_rate\n",
    "    b1 += np.sum(d_hidden2,axis=0) * learning_rate\n",
    "    \n",
    "    return y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
